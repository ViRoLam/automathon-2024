
Training model:
Traceback (most recent call last):
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/cuda/__init__.py", line 306, in _lazy_init
    queued_call()
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/cuda/__init__.py", line 174, in _check_capability
    capability = get_device_capability(d)
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/cuda/__init__.py", line 430, in get_device_capability
    prop = get_device_properties(device)
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/cuda/__init__.py", line 448, in get_device_properties
    return _get_device_properties(device)  # type: ignore[name-defined]
RuntimeError: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at "../aten/src/ATen/cuda/CUDAContext.cpp":50, please report a bug to PyTorch. device=, num_gpus=
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/raid/home/automathon_2024/account8/automathon-2024/run.py", line 304, in <module>
    summary(model, input_size=(batch_size, 3, 10, 256, 256))
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torchinfo/torchinfo.py", line 220, in summary
    x, correct_input_size = process_input(
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torchinfo/torchinfo.py", line 256, in process_input
    x = get_input_tensor(correct_input_size, batch_dim, dtypes, device)
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torchinfo/torchinfo.py", line 532, in get_input_tensor
    x.append(input_tensor.to(device).type(dtype))
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/cuda/__init__.py", line 312, in _lazy_init
    raise DeferredCudaCallError(msg) from e
torch.cuda.DeferredCudaCallError: CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at "../aten/src/ATen/cuda/CUDAContext.cpp":50, please report a bug to PyTorch. device=, num_gpus=
CUDA call was originally invoked at:
  File "/raid/home/automathon_2024/account8/automathon-2024/run.py", line 4, in <module>
    import torch
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/__init__.py", line 1478, in <module>
    _C._initExtension(manager_path())
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/cuda/__init__.py", line 238, in <module>
    _lazy_call(_check_capability)
  File "/raid/home/automathon_2024/account8/.local/lib/python3.10/site-packages/torch/cuda/__init__.py", line 235, in _lazy_call
    _queued_calls.append((callable, traceback.format_stack()))